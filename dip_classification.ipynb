{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aneesAyy/hello-world/blob/master/dip_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx9QmafgR2WS",
        "outputId": "531d7c12-dd1b-49e7-b619-037c8ebaa91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsZQY2pbSaJu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import math\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.losses import *\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzE5IhPPSgXZ",
        "outputId": "f8b16ccd-62cb-4c71-c565-1451ed677274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training images and training lables is:  (762, 256, 256, 3) , (762, 256, 256)\n",
            "Shape of testing images and testing lables is:  (76, 256, 256, 3) , (76, 256, 256)\n"
          ]
        }
      ],
      "source": [
        "training_file_path = '/content/drive/MyDrive/Colab Notebooks/Segmentation/train_images.npy'\n",
        "training_labels_path = '/content/drive/MyDrive/Colab Notebooks/Segmentation/training_labels_path.npy'\n",
        "testing_file_path = '/content/drive/MyDrive/Colab Notebooks/Segmentation/test_images.npy'\n",
        "testing_labels_path = '/content/drive/MyDrive/Colab Notebooks/Segmentation/testing_labels_path.npy'\n",
        "\n",
        "training_images, training_masks, testing_images, testing_masks = np.load(training_file_path), np.load(training_labels_path), np.load(testing_file_path), np.load(testing_labels_path) \n",
        "\n",
        "print('Shape of training images and training lables is: ', training_images.shape, ',', training_masks.shape)\n",
        "print('Shape of testing images and testing lables is: ', testing_images.shape, ',', testing_masks.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQQXMD5kY2SI",
        "outputId": "eda52dbd-8605-4aa5-96b4-6d17a0f4b80b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 256, 256, 16  448         ['input_3[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 256, 256, 16  64         ['conv2d_38[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_36[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 256, 256, 16  2320        ['activation_36[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 256, 256, 16  64         ['conv2d_39[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_37[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, 128, 128, 16  0          ['activation_37[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 128, 128, 32  4640        ['max_pooling2d_8[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 128, 128, 32  128        ['conv2d_40[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_38[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 128, 128, 32  9248        ['activation_38[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 128, 128, 32  128        ['conv2d_41[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_39[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (None, 64, 64, 32)  0           ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 64, 64, 64)   18496       ['max_pooling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 64, 64, 64)  256         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 64, 64, 64)   36928       ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 64, 64, 64)  256         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooling2D  (None, 32, 32, 64)  0           ['activation_41[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 32, 32, 128)  73856       ['max_pooling2d_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 32, 32, 128)  512        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 32, 32, 128)  147584      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 32, 32, 128)  512        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (None, 16, 16, 128)  0          ['activation_43[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 16, 16, 1024  1180672     ['max_pooling2d_11[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 16, 16, 1024  4096       ['conv2d_46[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 16, 16, 1024  0           ['batch_normalization_44[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 16, 16, 1024  9438208     ['activation_44[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 16, 16, 1024  4096       ['conv2d_47[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 16, 16, 1024  0           ['batch_normalization_45[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_8 (Conv2DTran  (None, 32, 32, 128)  524416     ['activation_45[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 32, 32, 256)  0           ['conv2d_transpose_8[0][0]',     \n",
            "                                                                  'activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 32, 32, 128)  295040      ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 32, 32, 128)  512        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 32, 32, 128)  147584      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 32, 32, 128)  512        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_9 (Conv2DTran  (None, 64, 64, 64)  32832       ['activation_47[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 64, 64, 128)  0           ['conv2d_transpose_9[0][0]',     \n",
            "                                                                  'activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 64, 64, 64)   73792       ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 64, 64, 64)  256         ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 64, 64, 64)   36928       ['activation_48[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 64, 64, 64)  256         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_10 (Conv2DTra  (None, 128, 128, 32  8224       ['activation_49[0][0]']          \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 128, 128, 64  0           ['conv2d_transpose_10[0][0]',    \n",
            "                                )                                 'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 128, 128, 32  18464       ['concatenate_10[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 128, 128, 32  128        ['conv2d_52[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_50[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 128, 128, 32  9248        ['activation_50[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 128, 128, 32  128        ['conv2d_53[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_51[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_11 (Conv2DTra  (None, 256, 256, 16  2064       ['activation_51[0][0]']          \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 256, 256, 32  0           ['conv2d_transpose_11[0][0]',    \n",
            "                                )                                 'activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 256, 256, 16  4624        ['concatenate_11[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 256, 256, 16  64         ['conv2d_54[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_52[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 256, 256, 16  2320        ['activation_52[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 256, 256, 16  64         ['conv2d_55[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 256, 256, 16  0           ['batch_normalization_53[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 256, 256, 1)  17          ['activation_53[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 12,079,985\n",
            "Trainable params: 12,073,969\n",
            "Non-trainable params: 6,016\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# https://idiotdeveloper.com/unet-implementation-in-tensorflow-using-keras-api/\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 16)\n",
        "    s2, p2 = encoder_block(p1, 32)\n",
        "    s3, p3 = encoder_block(p2, 64)\n",
        "    s4, p4 = encoder_block(p3, 128)\n",
        "\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 128)\n",
        "    d2 = decoder_block(d1, s3, 64)\n",
        "    d3 = decoder_block(d2, s2, 32)\n",
        "    d4 = decoder_block(d3, s1, 16)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    return model\n",
        "\n",
        "model = build_unet((256, 256, 3))\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HhgyteZuaBSy",
        "outputId": "3faee9db-856b-4911-e7d1-e1f8ab9a182c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n",
            "Epoch 1/50\n",
            "22/22 [==============================] - 30s 509ms/step - loss: -58.0250 - accuracy: 0.1400 - val_loss: -11.6114 - val_accuracy: 0.1745\n",
            "Epoch 2/50\n",
            "22/22 [==============================] - 8s 361ms/step - loss: -74.4157 - accuracy: 0.1673 - val_loss: -6.9461 - val_accuracy: 0.1251\n",
            "Epoch 3/50\n",
            "22/22 [==============================] - 8s 365ms/step - loss: -91.6743 - accuracy: 0.1956 - val_loss: -7.4131 - val_accuracy: 0.1414\n",
            "Epoch 4/50\n",
            "22/22 [==============================] - 8s 368ms/step - loss: -108.9823 - accuracy: 0.2278 - val_loss: -9.4133 - val_accuracy: 0.1665\n",
            "Epoch 5/50\n",
            "22/22 [==============================] - 8s 369ms/step - loss: -125.3673 - accuracy: 0.2597 - val_loss: -12.1942 - val_accuracy: 0.2038\n",
            "Epoch 6/50\n",
            "22/22 [==============================] - 8s 367ms/step - loss: -140.5677 - accuracy: 0.2832 - val_loss: -16.1568 - val_accuracy: 0.2615\n",
            "Epoch 7/50\n",
            "22/22 [==============================] - 8s 364ms/step - loss: -155.2950 - accuracy: 0.3039 - val_loss: -21.3351 - val_accuracy: 0.3292\n",
            "Epoch 8/50\n",
            "22/22 [==============================] - 8s 361ms/step - loss: -169.6240 - accuracy: 0.3284 - val_loss: -28.7377 - val_accuracy: 0.3624\n",
            "Epoch 9/50\n",
            "22/22 [==============================] - 8s 360ms/step - loss: -183.9056 - accuracy: 0.3551 - val_loss: -40.2655 - val_accuracy: 0.3839\n",
            "Epoch 10/50\n",
            "22/22 [==============================] - 8s 360ms/step - loss: -198.2376 - accuracy: 0.3790 - val_loss: -59.4432 - val_accuracy: 0.3934\n",
            "Epoch 11/50\n",
            "22/22 [==============================] - 8s 360ms/step - loss: -212.0573 - accuracy: 0.4010 - val_loss: -89.8264 - val_accuracy: 0.4054\n",
            "Epoch 12/50\n",
            "22/22 [==============================] - 8s 361ms/step - loss: -225.2534 - accuracy: 0.4235 - val_loss: -125.7434 - val_accuracy: 0.4038\n",
            "Epoch 13/50\n",
            "22/22 [==============================] - 8s 363ms/step - loss: -237.3116 - accuracy: 0.4474 - val_loss: -147.4390 - val_accuracy: 0.4100\n",
            "Epoch 14/50\n",
            "22/22 [==============================] - 8s 364ms/step - loss: -248.9021 - accuracy: 0.4745 - val_loss: -182.3779 - val_accuracy: 0.4287\n",
            "Epoch 15/50\n",
            "22/22 [==============================] - 8s 364ms/step - loss: -259.5742 - accuracy: 0.5016 - val_loss: -208.2386 - val_accuracy: 0.4740\n",
            "Epoch 16/50\n",
            "22/22 [==============================] - 8s 363ms/step - loss: -269.5165 - accuracy: 0.5260 - val_loss: -207.3907 - val_accuracy: 0.5165\n",
            "Epoch 17/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -278.5983 - accuracy: 0.5472 - val_loss: -219.3903 - val_accuracy: 0.5406\n",
            "Epoch 18/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -286.4619 - accuracy: 0.5639 - val_loss: -252.7697 - val_accuracy: 0.5516\n",
            "Epoch 19/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -293.8198 - accuracy: 0.5784 - val_loss: -239.9450 - val_accuracy: 0.5750\n",
            "Epoch 20/50\n",
            "22/22 [==============================] - 8s 361ms/step - loss: -300.3322 - accuracy: 0.5902 - val_loss: -248.6908 - val_accuracy: 0.5859\n",
            "Epoch 21/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -306.5822 - accuracy: 0.6016 - val_loss: -265.8369 - val_accuracy: 0.5969\n",
            "Epoch 22/50\n",
            "22/22 [==============================] - 8s 363ms/step - loss: -312.2275 - accuracy: 0.6121 - val_loss: -260.6041 - val_accuracy: 0.6087\n",
            "Epoch 23/50\n",
            "22/22 [==============================] - 8s 363ms/step - loss: -317.5346 - accuracy: 0.6214 - val_loss: -270.9479 - val_accuracy: 0.6190\n",
            "Epoch 24/50\n",
            "22/22 [==============================] - 8s 363ms/step - loss: -322.2948 - accuracy: 0.6300 - val_loss: -255.1170 - val_accuracy: 0.6349\n",
            "Epoch 25/50\n",
            "22/22 [==============================] - 8s 363ms/step - loss: -327.1840 - accuracy: 0.6386 - val_loss: -276.2121 - val_accuracy: 0.6395\n",
            "Epoch 26/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -331.7345 - accuracy: 0.6459 - val_loss: -284.6487 - val_accuracy: 0.6517\n",
            "Epoch 27/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -335.9910 - accuracy: 0.6527 - val_loss: -293.5536 - val_accuracy: 0.6542\n",
            "Epoch 28/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -339.8358 - accuracy: 0.6588 - val_loss: -299.8237 - val_accuracy: 0.6634\n",
            "Epoch 29/50\n",
            "22/22 [==============================] - 8s 363ms/step - loss: -343.7110 - accuracy: 0.6640 - val_loss: -299.3363 - val_accuracy: 0.6704\n",
            "Epoch 30/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -347.2749 - accuracy: 0.6687 - val_loss: -311.4821 - val_accuracy: 0.6739\n",
            "Epoch 31/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -350.8789 - accuracy: 0.6731 - val_loss: -309.9005 - val_accuracy: 0.6769\n",
            "Epoch 32/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -353.8947 - accuracy: 0.6764 - val_loss: -327.0941 - val_accuracy: 0.6798\n",
            "Epoch 33/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -357.0767 - accuracy: 0.6798 - val_loss: -335.7194 - val_accuracy: 0.6803\n",
            "Epoch 34/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -359.8994 - accuracy: 0.6819 - val_loss: -346.8759 - val_accuracy: 0.6847\n",
            "Epoch 35/50\n",
            "22/22 [==============================] - 8s 363ms/step - loss: -362.7421 - accuracy: 0.6845 - val_loss: -345.6945 - val_accuracy: 0.6854\n",
            "Epoch 36/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -365.2003 - accuracy: 0.6864 - val_loss: -340.3189 - val_accuracy: 0.6916\n",
            "Epoch 37/50\n",
            "22/22 [==============================] - 8s 363ms/step - loss: -367.4972 - accuracy: 0.6879 - val_loss: -334.5005 - val_accuracy: 0.6940\n",
            "Epoch 38/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -369.8109 - accuracy: 0.6903 - val_loss: -346.5098 - val_accuracy: 0.6958\n",
            "Epoch 39/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -371.9839 - accuracy: 0.6915 - val_loss: -361.3912 - val_accuracy: 0.6933\n",
            "Epoch 40/50\n",
            "22/22 [==============================] - 8s 363ms/step - loss: -374.1247 - accuracy: 0.6929 - val_loss: -372.0577 - val_accuracy: 0.6931\n",
            "Epoch 41/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -375.7934 - accuracy: 0.6942 - val_loss: -345.6656 - val_accuracy: 0.7033\n",
            "Epoch 42/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -377.7094 - accuracy: 0.6951 - val_loss: -354.4333 - val_accuracy: 0.7023\n",
            "Epoch 43/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -379.3936 - accuracy: 0.6964 - val_loss: -362.5305 - val_accuracy: 0.7003\n",
            "Epoch 44/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -380.8847 - accuracy: 0.6973 - val_loss: -370.1380 - val_accuracy: 0.7013\n",
            "Epoch 45/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -382.5439 - accuracy: 0.6983 - val_loss: -368.8449 - val_accuracy: 0.7004\n",
            "Epoch 46/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -384.0939 - accuracy: 0.6988 - val_loss: -367.7036 - val_accuracy: 0.7021\n",
            "Epoch 47/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -385.4179 - accuracy: 0.7000 - val_loss: -366.6526 - val_accuracy: 0.7038\n",
            "Epoch 48/50\n",
            "22/22 [==============================] - 8s 361ms/step - loss: -386.6387 - accuracy: 0.7004 - val_loss: -384.4836 - val_accuracy: 0.7004\n",
            "Epoch 49/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -387.9565 - accuracy: 0.7012 - val_loss: -380.4366 - val_accuracy: 0.7021\n",
            "Epoch 50/50\n",
            "22/22 [==============================] - 8s 362ms/step - loss: -389.0115 - accuracy: 0.7014 - val_loss: -367.0795 - val_accuracy: 0.7087\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f02b6b972de5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'file' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# metrics = [dice_coef, iou, Recall(), Precision()]\n",
        "my_optimiser = Adam(lr=0.00001)\n",
        "model.compile(loss='BinaryCrossentropy', optimizer=my_optimiser, metrics='accuracy')\n",
        "epochs = 50\n",
        "\n",
        "print('Training Models')\n",
        "\n",
        "my_model_history = model.fit(\n",
        "        x=training_images, y=training_masks, epochs=epochs, validation_split = 0.1)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "dip_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}